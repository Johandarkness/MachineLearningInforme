{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook2 \n",
    "\n",
    "En este notebook se realizarán las siguientes actividades:\n",
    "\n",
    "1. Leer el archivo stroke.csv\n",
    "2. Seleccionar aleatoriamente el 80% del conjunto de datos para entrenar y el 20% restante para las pruebas\n",
    "3. Utilizar una estrategia para normalizar los datos y llenar los datos faltantes\n",
    "4. Configurar los hiperparámetros del árbol de decisión de la siguiente manera: criterion=gini, splitter=best,\n",
    "y random_state=123. Obtener 10 árboles de decisión que resultan de modificar el hiperparámetro \n",
    "max_depth desde 5 hasta 50 con incrementos de 5\n",
    "5. Incluya en el notebook una tabla con el accuracy para los 10 árboles del punto anterior\n",
    "6. Repita el mismo procedimiento del punto 4 usando como hiperparámetros criterion=entropy, splitter=best, \n",
    "random_state=123, y variando el hiperparámetro max_depth desde 5 hasta 50 con incrementos de 5\n",
    "7. Incluya en el notebook una tabla con el accuracy para los 10 árboles del punto anterior\n",
    "8. Repita el mismo procedimiento del punto 4 usando como hiperparámetros criterion=entropy,\n",
    "splitter=random, random_state=123, y variando el hiperparámetro max_depth desde 5 hasta 50 con\n",
    "incrementos de 5\n",
    "9. Incluya en el notebook una tabla con el accuracy para los 10 árboles del punto anterior\n",
    "10. Indique en el notebook los hiperparámetros que por el momento le permiten obtener el árbol con mayor\n",
    "accuracy\n",
    "11. Seleccione uno de los hiperparámetros disponibles en la documentación\n",
    "(https://scikitlearn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "que sea diferente al criterion,\n",
    "splitter, max_depth, y random_state. Realice dos variaciones en el hiperparámetro seleccionado\n",
    "manteniendo los otros hiperparámetros del punto anterior. Indique el accuracy obtenido al modificar el\n",
    "hiperparámetro seleccionado y analice si el árbol de decisión mejora, empeora, o mantiene su exactitud.\n",
    "\n",
    "Y se analizará al final los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "\n",
    "# Ignorar las advertencias\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Paso 1: Leer el archivo stroke.csv\n",
    "datos = pd.read_csv('stroke.csv')\n",
    "\n",
    "# Paso 2: Seleccionar aleatoriamente el 80% del conjunto de datos para entrenar y el 20% restante para las pruebas\n",
    "X_train, X_test, y_train, y_test = train_test_split(datos.drop('stroke', axis=1), datos['stroke'], test_size=0.2, random_state=123)\n",
    "\n",
    "# Paso 3: llenar los datos faltantes y normalizar los datos\n",
    "categoricas = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "numericas = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "# Codificar variables categóricas usando LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for categoria in categoricas:\n",
    "    X_train[categoria] = label_encoder.fit_transform(X_train[categoria])\n",
    "    X_test[categoria] = label_encoder.transform(X_test[categoria])\n",
    "\n",
    "# Llenar los datos faltantes con la media usando SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train[numericas] = imputer.fit_transform(X_train[numericas])\n",
    "X_test[numericas] = imputer.transform(X_test[numericas])\n",
    "\n",
    "\n",
    "# Paso 4: Configurar los hiperparámetros del árbol de decisión (criterion=gini, splitter=best, random_state=123)\n",
    "hiperparametros = {\n",
    "    'criterion': 'gini',\n",
    "    'splitter': 'best',\n",
    "    'random_state': 123\n",
    "}\n",
    "\n",
    "resultados_1 = []\n",
    "\n",
    "for max_depth in range(5, 51, 5):\n",
    "    hiperparametros['max_depth'] = max_depth\n",
    "    modelo = DecisionTreeClassifier(**hiperparametros)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    resultados_1.append((max_depth, accuracy))\n",
    "\n",
    "# Paso 5: Mostrar una tabla con el accuracy para los 10 árboles\n",
    "tabla1 = pd.DataFrame(resultados_1, columns=['max_depth', 'Accuracy (criterion=gini)'])\n",
    "print(\"Tabla 1: Accuracy para los árboles con criterion=gini\")\n",
    "print(tabla1)\n",
    "print(\"\\n\",\"#####################################################################\",\"\\n\")\n",
    "\n",
    "# Paso 6: Configurar los hiperparámetros del árbol de decisión (criterion=entropy, splitter=best, random_state=123)\n",
    "hiperparametros2 = {\n",
    "    'criterion': 'entropy',\n",
    "    'splitter': 'best',\n",
    "    'random_state': 123\n",
    "}\n",
    "\n",
    "resultados_2 = []\n",
    "\n",
    "for max_depth in range(5, 51, 5):\n",
    "    hiperparametros2['max_depth'] = max_depth\n",
    "    modelo = DecisionTreeClassifier(**hiperparametros2)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    resultados_2.append((max_depth, accuracy))\n",
    "\n",
    "# Paso 7: Mostrar una tabla con el accuracy para los 10 árboles\n",
    "tabla2 = pd.DataFrame(resultados_2, columns=['max_depth', 'Accuracy (criterion=entropy)'])\n",
    "print(\"Tabla 2: Accuracy para los árboles con criterion=entropy\")\n",
    "print(tabla2)\n",
    "print(\"\\n\",\"#####################################################################\",\"\\n\")\n",
    "\n",
    "# Paso 8: Configurar los hiperparámetros del árbol de decisión (criterion=entropy, splitter=random, random_state=123)\n",
    "hiperparametros3 = {\n",
    "    'criterion': 'entropy',\n",
    "    'splitter': 'random',\n",
    "    'random_state': 123\n",
    "}\n",
    "\n",
    "resultados_3 = []\n",
    "\n",
    "for max_depth in range(5, 51, 5):\n",
    "    hiperparametros3['max_depth'] = max_depth\n",
    "    modelo = DecisionTreeClassifier(**hiperparametros3)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    resultados_3.append((max_depth, accuracy))\n",
    "\n",
    "# Paso 7: Mostrar una tabla con el accuracy para los 10 árboles\n",
    "tabla3 = pd.DataFrame(resultados_3, columns=['max_depth', 'Accuracy(splitter=random)'])\n",
    "print(\"Tabla 3: Accuracy para los árboles con splitter=random\")\n",
    "print(tabla3)\n",
    "print(\"\\n\",\"#####################################################################\",\"\\n\")\n",
    "\n",
    "# Encontrar los hiperparámetros que generan el árbol con mayor precisión (accuracy)\n",
    "mejor_1 = tabla1.loc[tabla1['Accuracy (criterion=gini)'].idxmax()]\n",
    "mejor_2 = tabla2.loc[tabla2['Accuracy (criterion=entropy)'].idxmax()]\n",
    "mejor_3 = tabla3.loc[tabla3['Accuracy(splitter=random)'].idxmax()]\n",
    "\n",
    "# Mostrar los hiperparámetros que generan el árbol con mayor precisión\n",
    "print(\"Hiperparámetros con mayor precisión (criterion=gini):\")\n",
    "print(mejor_1[['max_depth', 'Accuracy (criterion=gini)']])\n",
    "print()\n",
    "print(\"\\n\",\"#####################################################################\",\"\\n\")\n",
    "\n",
    "print(\"Hiperparámetros con mayor precisión (criterion=entropy):\")\n",
    "print(mejor_2[['max_depth', 'Accuracy (criterion=entropy)']])\n",
    "print()\n",
    "print(\"\\n\",\"#####################################################################\",\"\\n\")\n",
    "\n",
    "print(\"Hiperparámetros con mayor precisión (splitter=random):\")\n",
    "print(mejor_3[['max_depth', 'Accuracy(splitter=random)']])\n",
    "print()\n",
    "print(\"\\n\",\"#####################################################################\",\"\\n\")\n",
    "\n",
    "# Paso 8: Configurar los hiperparámetros del árbol de decisión (criterion=entropy, splitter=random, random_state=123)\n",
    "hiperparametros3 = {\n",
    "    'criterion': 'entropy',\n",
    "    'splitter': 'random',\n",
    "    'random_state': 123,\n",
    "    'min_samples_split': 2  # Cambiar el valor de min_samples_split en el caso 1\n",
    "}\n",
    "\n",
    "resultados_3_1 = []\n",
    "\n",
    "for max_depth in range(5, 51, 5):\n",
    "    hiperparametros3['max_depth'] = max_depth\n",
    "    modelo = DecisionTreeClassifier(**hiperparametros3)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    resultados_3_1.append((max_depth, accuracy))\n",
    "\n",
    "# Mostrar una tabla con el accuracy para los 10 árboles\n",
    "tabla3_1 = pd.DataFrame(resultados_3_1, columns=['max_depth', 'Accuracy(splitter=random, min_samples_split=2)'])\n",
    "print(\"Tabla 3_1: Accuracy para los árboles con splitter=random y min_samples_split=2\")\n",
    "print(tabla3_1)\n",
    "print()\n",
    "print(\"\\n\",\"#####################################################################\",\"\\n\")\n",
    "\n",
    "# Configurar el valor de min_samples_split en el caso 2\n",
    "hiperparametros3['min_samples_split'] = 10\n",
    "\n",
    "resultados_3_2 = []\n",
    "\n",
    "for max_depth in range(5, 51, 5):\n",
    "    hiperparametros3['max_depth'] = max_depth\n",
    "    modelo = DecisionTreeClassifier(**hiperparametros3)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    resultados_3_2.append((max_depth, accuracy))\n",
    "\n",
    "# Mostrar una tabla con el accuracy para los 10 árboles\n",
    "tabla3_2 = pd.DataFrame(resultados_3_2, columns=['max_depth', 'Accuracy(splitter=random, min_samples_split=10)'])\n",
    "print(\"Tabla 3_2: Accuracy para los árboles con splitter=random y min_samples_split=10\")\n",
    "print(tabla3_2)\n",
    "print()\n",
    "print(\"\\n\",\"#####################################################################\",\"\\n\")\n",
    "\n",
    "# Obtener el valor máximo de precisión para cada tabla\n",
    "max_accuracy_3_1 = tabla3_1['Accuracy(splitter=random, min_samples_split=2)'].max()\n",
    "max_accuracy_3_2 = tabla3_2['Accuracy(splitter=random, min_samples_split=10)'].max()\n",
    "\n",
    "\n",
    "\n",
    "# Determinar cuál tabla tiene el mejor accuracy\n",
    "if max_accuracy_3_1 > max_accuracy_3_2:\n",
    "    mejor_tabla = 'Tabla 3_1: Accuracy con splitter=random y min_samples_split=2'\n",
    "    mejor_accuracy = max_accuracy_3_1\n",
    "else:\n",
    "    mejor_tabla = 'Tabla 3_2: Accuracy con splitter=random y min_samples_split=10'\n",
    "    mejor_accuracy = max_accuracy_3_2\n",
    "\n",
    "\n",
    "print(\"\\n\",\"#####################################################################\",\"\\n\")\n",
    "# Mostrar el resultado del mejor accuracy\n",
    "print(\"El árbol de decisión modificado con el mejor accuracy se encuentra en:\")\n",
    "print(mejor_tabla)\n",
    "print(\"El mejor accuracy obtenido es:\", mejor_accuracy)\n",
    "\n",
    "max_accuracy_1 = tabla1['Accuracy (criterion=gini)'].max()\n",
    "max_accuracy_2 = tabla2['Accuracy (criterion=entropy)'].max()\n",
    "max_accuracy_3 = tabla3['Accuracy(splitter=random)'].max()\n",
    "\n",
    "# Determinar cuál tabla tiene el mejor accuracy\n",
    "if max_accuracy_1 > max_accuracy_2 and max_accuracy_1 > max_accuracy_3:\n",
    "    mejor_tabla = 'Tabla 1: Accuracy con criterion=gini'\n",
    "    mejor_accuracy = max_accuracy_1\n",
    "elif max_accuracy_2 > max_accuracy_1 and max_accuracy_2 > max_accuracy_3:\n",
    "    mejor_tabla = 'Tabla 2: Accuracy con criterion=entropy'\n",
    "    mejor_accuracy = max_accuracy_2\n",
    "else:\n",
    "    mejor_tabla = 'Tabla 3: Accuracy con splitter=random'\n",
    "    mejor_accuracy = max_accuracy_3\n",
    "print(\"\\n\",\"#####################################################################\",\"\\n\")\n",
    "# Mostrar el resultado del mejor accuracy\n",
    "print(\"El árbol de decisión con el mejor accuracy se encuentra en:\")\n",
    "print(mejor_tabla)\n",
    "print(\"El mejor accuracy obtenido es:\", mejor_accuracy)\n",
    "print(\"\\n\",\"#####################################################################\",\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
